---
title: "automatization_notebook_04"
output:
  html_document:
    df_print: paged
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

setwd("C:/Users/enami/Downloads/biostat_homework_092024/")
knitr::opts_knit$set(root.dir = "C:/Users/enami/Downloads/biostat_homework_092024/")
```

# Чтение данных

В вашем варианте нужно использовать датасет healthcare-dataset-stroke-data.

```{r}

data <- read.csv('./data/raw/healthcare-dataset-stroke-data.csv', sep = ',', header = TRUE)
#пусть id из первого столбца будут названиями строк:
rownames(data) <- data$id
data <- data[,-1]
head(data)
```

# Выведите общее описание данных

```{r}
dim(data) #сколько строк, сколько столбцов
str(data)
summary(data)
```

# Очистка данных: начало

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант.

Сначала все-таки приведем данные к нужному типу, а потом займемся пропусками:
```{r}
data$gender <- as.factor(data$gender)
data$age <- as.integer(data$age)
data$hypertension <- as.factor(data$hypertension)
data$heart_disease <- as.factor(data$heart_disease)
data$ever_married <- as.factor(data$ever_married)
data$work_type <- as.factor(data$work_type)
data$Residence_type <- as.factor(data$Residence_type)
data$avg_glucose_level <- as.numeric(data$avg_glucose_level)
data$bmi <- as.numeric(data$bmi)
data$smoking_status <- as.factor(data$smoking_status)
data$stroke <- as.factor(data$stroke)
```

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
str(data)
summary(data)
```
Мы видим, что: 

- в столбце gender имеется один случай с gender=Other,

- в столбце bmi есть **201 пропуск** (NA), что составляет `r paste0(round(201/dim(data)[1]*100, 2), "%")` от общего числа субъектов, 

- в столбце smoking_status есть **1544 пропуска** (Unknown), что составляет `r paste0(round(1544/dim(data)[1]*100, 2), "%")` от общего числа субъектов.

Теперь посмотрим, сколько субъектов имеют пропущенные значения одновременно для bmi и smoking_status.
```{r}
dim(data %>%
  filter(is.na(bmi) & smoking_status == "Unknown"))[1]
```

Итак, субъектов с пропусками в 2 столбцах имеется **61 человек**, что составляет `r paste0(round(dim(data %>% filter(is.na(bmi) & smoking_status == "Unknown"))[1]/dim(data)[1]*100, 2), "%")` от общего числа субъектов, что очень мало. 

**Обоснование дальнейшей очистки:**
Доля субъектов с пропусками 2 столбцах очень мала и удаление таких наблюдений не приведет к сильной потере данных. Также стоит удалить субъекта с gender=Other, так как 1 наблюдения в любом случае не будет достаточно для получения статистически значимых выводов об особенностях субъектов с данным полом. Что касается переменных с пропусками (bmi, smoking_status), стоит удалить переменную  smoking_status, так как доля пропусков в ней достаточно велика (больше 20%), и если удалить субъектов с пропуском smoking_status, субъектов останется намного меньше. Доля пропусков в переменной bmi мала и не стоит удалять ее, ведь она может оказаться важным фактором.
Итак, нужно сначала удалить переменную smoking_status, а потом субъектов со значением пола Other и пропуском в индексе масса тела. 

# Очистка данных: продолжение

```{r}
data2 <- data
data2$smoking_status <- NULL
data2 <- data2 %>%
  filter(gender != "Other" & !is.na(bmi))
data2 <- droplevels(data2)
```


# Сколько осталось переменных?

```{r}
dim(data2)[2]
```

# Сколько осталось случаев?

```{r}
dim(data2)[1]
```

2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

Пробелы в названиях имелись только для значений переменной smoking_status, которая была удалена. Осталось переименовать одну из колонок для большей однотипности:
```{r}
names(data2)[names(data2) == 'Residence_type'] <- 'residence_type'
```

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);
(было выполнено выше)

4) Отсортируйте данные по возрасту по убыванию;
```{r}
data3 <- data2 %>%
  arrange(desc(age))
```

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

Создадим датасеты с выбросами отдельно по age, avg_glucose_level и bmi, и посмотрим число оставшихся субъектов:
```{r}
data3_outliers_by_age <- data3 %>%
  filter(age >= mean(data3$age) + 3*sd(data3$age) | age <= mean(data3$age) - 3*sd(data3$age))

dim(data3_outliers_by_age)[1]

data3_outliers_by_avg_glucose_level <- data3 %>%
  filter(avg_glucose_level >= mean(data3$avg_glucose_level) + 3*sd(data3$avg_glucose_level) | avg_glucose_level <= mean(data3$avg_glucose_level) - 3*sd(data3$avg_glucose_level))

dim(data3_outliers_by_avg_glucose_level)[1]

data3_outliers_by_bmi <- data3 %>%
  filter(bmi >= mean(data3$bmi) + 3*sd(data3$bmi) | bmi <= mean(data3$bmi) - 3*sd(data3$bmi))
         
dim(data3_outliers_by_bmi)[1]
```

Теперь соединим датасеты и удалим у итогового строки-дубликаты:
```{r}
data3_outliers <- rbind(data3_outliers_by_avg_glucose_level, data3_outliers_by_bmi)
sum(duplicated(data3_outliers))
data3_outliers <- data3_outliers[!duplicated(data3_outliers), ]
```


```{r}
write.csv(data3_outliers, file = 'outliers.csv')
```

6) Присвойте получившийся датасет переменной "cleaned_data".
```{r}
cleaned_data <- data3
```

# Есть ли в данных идентичные строки?

```{r}
sum(duplicated(data))
sum(duplicated(cleaned_data))
```
Идентичных строк нет ни в исходном датасете, не в конечном.

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (stroke):

1.1) Количество значений;

Рассчитаем отдельно для исходного датасета, и для конечного (почищенного).
```{r}
rows_count <- function(df) {
  number_of_rows <- df %>%
    group_by(stroke) %>%
    count()
  return(number_of_rows)
}

rows_count(data)
rows_count(cleaned_data)

```
1.2) Количество пропущенных значений;

Рассчитаем отдельно для исходного датасета, и для конечного (почищенного).
```{r}

na_count <- function(df, colname) {
  number_of_na <- df %>%
    group_by(stroke) %>%
    filter(is.na({{colname}})) %>%
    count()
  return(number_of_na)
}

na_count(data, age)
na_count(data, avg_glucose_level)
na_count(data, bmi)

na_count(cleaned_data, age)
na_count(cleaned_data, avg_glucose_level)
na_count(cleaned_data, bmi)

```
Пропущенные значения есть только для bmi до очистки. После очистки пропущенных значений нет - она прошла успешно.

1.3) Среднее;
```{r}
mean_calc <- function(df, colname) {
  means <- df %>%
    group_by(stroke) %>%
    summarise(mean = mean({{colname}}))
  return(means)
}

mean_calc(cleaned_data, age)
mean_calc(cleaned_data, avg_glucose_level)
mean_calc(cleaned_data, bmi)
```
1.4) Медиану;
```{r}
median_calc <- function(df, colname) {
  medians <- df %>%
    group_by(stroke) %>%
    summarise(median = median({{colname}}))
  return(medians)
}

median_calc(cleaned_data, age)
median_calc(cleaned_data, avg_glucose_level)
median_calc(cleaned_data, bmi)
```

1.5) Стандартное отклонение;

```{r}
sd_calc <- function(df, colname) {
  sds <- df %>%
    group_by(stroke) %>%
    summarise(sd = sd({{colname}}))
  return(sds)
}

sd_calc(cleaned_data, age)
sd_calc(cleaned_data, avg_glucose_level)
sd_calc(cleaned_data, bmi)
```

1.6) 25% квантиль и 75% квантиль;
```{r}
quantile_calc <- function(df, colname) {
  quantiles <- df %>%
    group_by(stroke) %>%
    reframe(quantile = quantile({{colname}}, probs = c(0.25, 0.75)))
  return(quantiles)
}

quantile_calc(cleaned_data, age)
quantile_calc(cleaned_data, avg_glucose_level)
quantile_calc(cleaned_data, bmi)
```
1.7) Интерквартильный размах;

```{r}
IQR_calc <- function(df, colname) {
  IQRs <- df %>%
    group_by(stroke) %>%
    reframe(IQR = IQR({{colname}}))
  return(IQRs)
}

IQR_calc(cleaned_data, age)
IQR_calc(cleaned_data, avg_glucose_level)
IQR_calc(cleaned_data, bmi)
```

1.8) Минимум;
```{r}
min_calc <- function(df, colname) {
  mins <- df %>%
    group_by(stroke) %>%
    summarise(min = min({{colname}}))
  return(mins)
}

min_calc(cleaned_data, age)
min_calc(cleaned_data, avg_glucose_level)
min_calc(cleaned_data, bmi)
```
1.9) Максимум;
```{r}
max_calc <- function(df, colname) {
  maxs <- df %>%
    group_by(stroke) %>%
    summarise(max = max({{colname}}))
  return(maxs)
}

max_calc(cleaned_data, age)
max_calc(cleaned_data, avg_glucose_level)
max_calc(cleaned_data, bmi)
```
1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}
confint_calc <- function(df, colname) {
  confints <- df %>%
    group_by(stroke) %>%
    reframe(confint = t.test({{colname}})$conf.int)
  return(confints)
}

confint_calc(cleaned_data, age)
confint_calc(cleaned_data, avg_glucose_level)
confint_calc(cleaned_data, bmi)
```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (stroke):


1.1) Абсолютное количество;
Рассчитаем отдельно для исходного датасета, и для конечного (почищенного).
```{r}

rows_types_count <- function(df, colname) {
  number_of_rows_types <- df %>%
    group_by(stroke, {{colname}}) %>%
    count()
  return(number_of_rows_types)
}

print(rows_types_count(data, gender))
rows_types_count(data, hypertension)
rows_types_count(data, heart_disease)
rows_types_count(data, ever_married)
rows_types_count(data, work_type)
rows_types_count(data, Residence_type)
rows_types_count(data, smoking_status)

rows_types_count(cleaned_data, gender)
rows_types_count(cleaned_data, hypertension)
rows_types_count(cleaned_data, heart_disease)
rows_types_count(cleaned_data, ever_married)
rows_types_count(cleaned_data, work_type)
rows_types_count(cleaned_data, residence_type)

```

1.2) Относительное количество внутри группы;

```{r}

rows_types_proportion <- function(df, colname) {
  proportion_of_rows_types <- df %>%
    group_by(stroke, {{colname}}) %>%
    summarise(n=n()) %>%
    mutate(proportion = n/sum(n))
  return(proportion_of_rows_types)
}

print(rows_types_proportion(data, gender))
rows_types_proportion(data, hypertension)
rows_types_proportion(data, heart_disease)
rows_types_proportion(data, ever_married)
rows_types_proportion(data, work_type)
rows_types_proportion(data, Residence_type)
rows_types_proportion(data, smoking_status)

rows_types_proportion(cleaned_data, gender)
rows_types_proportion(cleaned_data, hypertension)
rows_types_proportion(cleaned_data, heart_disease)
rows_types_proportion(cleaned_data, ever_married)
rows_types_proportion(cleaned_data, work_type)
rows_types_proportion(cleaned_data, residence_type)

```

Простой способ получить те же результаты не вручную:
```{r}
skimr::skim(data)
```

```{r}
skimr::skim(cleaned_data)
```

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r}
library(RColorBrewer)
library(ggplot2)

boxes <- cleaned_data %>% 
  select("age", "avg_glucose_level", "bmi") %>%
  pivot_longer(everything(),
               names_to = "item",
               values_to = "scores") %>% 
  ggplot(aes(x = scores, color = item)) +
  geom_boxplot() +
  labs(y = "", x="") +
  theme(legend.position = "none") +
  facet_wrap(~item,scales = "free")

boxes + scale_color_brewer(palette="Dark2")
 


```

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

Имеется достаточно мало категорий каждой переменной (в основном - 2 штуки), поэтому наилучшим образом подходит geom_bar. 
```{r}

bars <- cleaned_data %>% 
  select("gender", "hypertension", "heart_disease", "ever_married", "work_type", "residence_type") %>%
  pivot_longer(everything(),
               names_to = "item",
               values_to = "scores") %>% 
  ggplot(aes(x = scores, color = item)) +
  geom_bar(fill = "lightblue") +
  labs(y = "", x="") +
  theme(legend.position = "none") +
  facet_wrap(~item,scales = "free") +
  coord_flip()

bars + scale_color_brewer(palette="Dark2")

```


# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}
shapiro.test(cleaned_data[['age']])
shapiro.test(cleaned_data[['avg_glucose_level']])
shapiro.test(cleaned_data[['bmi']])
```
Тест Шапиро-Уилка показывает отсутствие нормальности распределения age, avg_glucose_level и bmi: Так как p-value меньше, чем уровень значимости 0.05 (< 2e-16), у нас есть основания отвергнуть нулевую гипотезу о том, данные распределены нормально.


2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r}
par(mfrow = c(1,3))

qqnorm(cleaned_data[['age']])
qqline(cleaned_data[['age']], col = "blue") #добавление теоретической линии, соответствующей нормальному распределению

qqnorm(cleaned_data[['avg_glucose_level']])
qqline(cleaned_data[['avg_glucose_level']], col = "blue")

qqnorm(cleaned_data[['bmi']])
qqline(cleaned_data[['bmi']], col = "blue")
```
Во всех трех случаях точки, построенные по нашим данным, отклоняются от теоретической линии, соответствующей нормальному распределению, то есть данные не распределены нормально. Это сходится с результатами теста Шапиро-Уилка.

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

Во-первых, можно построить обычную гистограмму и визуально оценить, напоминает ли распределение нормальное.

Во-вторых, можно провести тест Колмогорова-Смирнова, но он предназначен только для непрерывных данных и чувствителен к длине выборки (размер выборки не менее 50, при 25-50 можно использовать с поправкой Большева).

В-третьих, можно провести тест Андерсона-Дарлинга - он также чувствителен к длине выборки, но в меньшей степени (размер выборки не менее 8).


## Сравнение групп

1) Сравните группы (переменная **stroke**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

Начнем с количественных переменных - age, avg_glucose_level и bmi. Так как распределение не является нормальным, используем не z.test, а t.test.
```{r}
stroke1_age <- cleaned_data[cleaned_data$stroke == "1", ]$age
stroke0_age <- cleaned_data[cleaned_data$stroke == "0", ]$age
t.test(x = stroke1_age, y = stroke0_age, alternative = "two.sided")

stroke1_avg_glucose_level <- cleaned_data[cleaned_data$stroke == "1", ]$avg_glucose_level
stroke0_avg_glucose_level <- cleaned_data[cleaned_data$stroke == "0", ]$avg_glucose_level
t.test(x = stroke1_avg_glucose_level, y = stroke0_avg_glucose_level, alternative = "two.sided")

stroke1_bmi <- cleaned_data[cleaned_data$stroke == "1", ]$bmi
stroke0_bmi <- cleaned_data[cleaned_data$stroke == "0", ]$bmi
t.test(x = stroke1_bmi, y = stroke0_bmi, alternative = "two.sided")
```
Для age: Так как p-value меньше, чем уровень значимости 0.05 (< 2e-16), у нас есть основания отвергнуть нулевую гипотезу о том, что реальное различие в средних равно 0, и принять альтернативную гипотезу о том, что реальное различие в среднем возрасте между субъектами, испытавшими удар, и не испытавшими удар, не равно 0. При этом у испытавших удар средний возраст больше.

Для avg_glucose_level: Так как p-value меньше, чем уровень значимости 0.05 (< 2e-16), у нас есть основания отвергнуть нулевую гипотезу о том, что реальное различие в средних равно 0, и принять альтернативную гипотезу о том, что реальное различие в среднем уровне глюкозы между субъектами, испытавшими удар, и не испытавшими удар, не равно 0. При этом у испытавших удар средний уровень глюкозы больше.

Для bmi: Так как p-value больше, чем уровень значимости 0.05 (0.0003377), у нас нет основания отвергнуть нулевую гипотезу о том, что реальное различие в средних равно 0.

Далее проанализируем категориальные переменные. Так как количество наблюдений в каждой клетке сводных таблиц ниже больше 5, можно применить тест хи-квадрат, а не точный тест Фишера. 
```{r}
print("gender")
d1 <- table(cleaned_data$stroke, cleaned_data$gender)
d1
chisq.test(d1)

print("hypertension")
d2 <- table(cleaned_data$stroke, cleaned_data$hypertension)
d2
chisq.test(d2)

print("heart_disease")
d3 <- table(cleaned_data$stroke, cleaned_data$heart_disease)
d3
chisq.test(d3)

print("ever_married")
d4 <- table(cleaned_data$stroke, cleaned_data$ever_married)
d4
chisq.test(d4)

print("residence_type")
d6 <- table(cleaned_data$stroke, cleaned_data$residence_type)
d6
chisq.test(d6)
```
Для gender, residence_type: Так как p-value больше, чем уровень значимости 0.05, у нас нет основания отвергнуть нулевую гипотезу о том, что факторы наличие удара и пол, наличие удара и тип местожительства независимы.

Для hypertension, heart_disease, ever_married: Так как p-value меньше, чем уровень значимости 0.05, у нас есть основания отвергнуть нулевую гипотезу о том, что факторы наличие удара и гипертензии, наличие удара и болезни сердца, наличие удара и факт женитьбы независимы.

В случае типа работы в некоторых ячейках сводной таблицы есть значение меньше 5:
```{r}
print("work_type")
d5 <- table(cleaned_data$stroke, cleaned_data$work_type)
d5
fisher.test(d5, workspace=2e9)
```
Для hypertension, heart_disease, ever_married: Так как p-value меньше, чем уровень значимости 0.05, у нас есть основания отвергнуть нулевую гипотезу о том, что факторы наличие удара и тип работы независимы.


# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

Применим непараметрический метод Спирмена, а не параметрический метод Пирсона, так как данные не распределены нормально:
```{r}
library(corrplot) 
cors <- cor(cleaned_data[,c("age", "avg_glucose_level", "bmi")], method = "spearman")
corrplot(cors, type = "upper", method="color")
```

Корреляция - это статистическая взаимосвязь двух и более величин, при которой изменение одной или нескольких из этих величин сопутствует систематическому изменению значений другой или других величин. Корреляционный анализ позволяет лишь установить факт наличия связи между переменными, но не может доказать причинно-следственной зависимости. Полученные значения - сила корреляционной связи. Особенно неудобно то, что многие методы (в т.ч. метод Пирсона) улавливают только линейные связи. Кроме того, его обычно применяют для количественных данных. Однако, корреляционный анализ часто используют в разведочном анализе (например, до построения модели регрессии, чтобы заранее представлять, какие факторы могут оказаться значимыми). 

## Моделирование

1) Постройте регрессионную модель для переменной **stroke**. Опишите процесс построения

Так как stroke является категориальной переменной, необходимо применить не лийнейную, а бинарную логистическую регрессию. 
```{r}

model2 <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + residence_type + avg_glucose_level + bmi, data = cleaned_data, family = "binomial")
summary(model2)
```
**Интепретация:**

1. Коэффициенты. 

- Пол: Так как p-value больше, чем уровень значимости 0.05 (0.972298), у нас нет оснований отвергнуть нулевую гипотезу о том, что факт удара не зависит от пола.
- Аналогично для всех остальных переменных, кроме возраста.

- Возраст: Так как p-value меньше, чем уровень значимости 0.05 (< 2e-16), у нас есть основания отвергнуть нулевую гипотезу о том, что факт удара не зависит от индекса СЭС. То есть возраст предсказывает факт удара, то есть у субъектов с большим возрастом вероятность иметь удар больше.


2. Качество модели.
Предскажем вероятность планирования высшего образования согласно нашей модели и выведем точность:
```{r}
cleaned_data$probabilities2 <- predict(model2, type = "response", newdata= cleaned_data) 
summary(cleaned_data$probabilities2)
cleaned_data$classification2 <- ifelse(cleaned_data$probabilities2 > 0.5, 1, 0)
accuracy <- mean(cleaned_data$classification2 == cleaned_data$stroke)
accuracy
```
Точность модели = 95.74%, то есть достаточно высока.


**Проверим допущения бинарной логистической регрессии:**

Вспомним допущения линейной:
1. Линейная взаимосвязь между переменными. - не требуется. Но требуется линейная взаимосвязь между независимыми переменными и логитом результата!
2. Нормальное распределение остатков и ошибки не носят систематического характера - не требуется.
3. Гомоскедастичность - не требуется.
4. Ошибки некоррелированы: 𝐶𝑜𝑣(𝜖𝑖,𝜖𝑗) = 0 (отсутствие автокорреляции) - требуется!
5. Отсутствие мультиколлениарности (vif) - требуется!
6. Нормальное распределение переменных - не требуется.

1. Сглаженные графики показывают, что возраст линейно связаны с предсказываемым значением по логит-шкале:
```{r}
mycleaned_data <- select(cleaned_data, age, probabilities2)
mycleaned_data <- mycleaned_data  %>%
  mutate(logit = log(probabilities2/(1-probabilities2))) %>%
  select(-probabilities2) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mycleaned_data, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")
```

4. Однако, можно говорить о том, что есть положительная автокорреляция ошибок, что видно по тесту Дарбна-Уотсона (DW < 2):
```{r}
lmtest::dwtest(model2)
```

5. Можно говорить об отсутствии мультиколлинеарности, что видно по тому, что все значения меньше 5 и близки к 1:
```{r}
library(car)
vif(model2)
```

Таким образом, одно из допущений бинарной логистической регрессии не выполняется, однако данный анализ можно использовать для планирования дальнейших исследований.